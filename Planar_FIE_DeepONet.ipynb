{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = pd.read_excel('normaldata.xlsx', header = None).to_numpy()\n",
    "random = pd.read_excel('randomdata.xlsx', header = None).to_numpy()\n",
    "\n",
    "normalt = pd.read_excel('normalt.xlsx', header = None).to_numpy()\n",
    "randomt = pd.read_excel('randomt.xlsx', header = None).to_numpy()\n",
    "\n",
    "normalkapa = pd.read_excel('normalkapa.xlsx', header = None).to_numpy()\n",
    "randomkapa = pd.read_excel('randomkapa.xlsx', header = None).to_numpy()\n",
    "\n",
    "normalkapaori = pd.read_excel('normalkapaori.xlsx', header = None).to_numpy()\n",
    "randomkapaori = pd.read_excel('randomkapaori.xlsx', header = None).to_numpy()\n",
    "\n",
    "normal = torch.from_numpy(normal).float().to(device)\n",
    "random = torch.from_numpy(random).float().to(device)\n",
    "\n",
    "normalt = torch.from_numpy(normalt).float().to(device)\n",
    "randomt = torch.from_numpy(randomt).float().to(device)\n",
    "\n",
    "normalkapa = torch.from_numpy(normalkapa).float().to(device)\n",
    "randomkapa = torch.from_numpy(randomkapa).float().to(device)\n",
    "\n",
    "normalkapaori = torch.from_numpy(normalkapaori).float().to(device)\n",
    "randomkapaori = torch.from_numpy(randomkapaori).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get lengths of all tubes\n",
    "normallength = (normalt[:, 9] + normalt[:, 19] + normalt[:, 29]) * normal[:, 4] + 1 / normal[:, 6] * normal[:, 11] / 180 * np.pi + 1 / normal[:, 7] * normal[:, 12] / 180 * np.pi\n",
    "randomlength = (randomt[:, 109] + randomt[:, 119]) * random[:, 4]\n",
    "\n",
    "normallength = normallength.unsqueeze(1)\n",
    "randomlength = randomlength.unsqueeze(1)\n",
    "\n",
    "normallength_normalize = normallength / 1000\n",
    "randomlength_normalize = randomlength / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "index1 = [0, 1, 2, 3, 4, 5, 13]\n",
    "index2 = [0, 1, 2, 3, 4, 5, 19]\n",
    "\n",
    "feature1 = normal[:, index1]\n",
    "kapaori1 = normalkapaori * 100\n",
    "kapa1 = normalkapa * 100\n",
    "\n",
    "feature2 = random[:, index2]\n",
    "kapaori2 = randomkapaori * 100\n",
    "kapa2 = randomkapa * 100\n",
    "\n",
    "ranges = [(20, 35), (0.075, 0.1), (1.3, 1.6), (1.05, 1.35), (40, 100), (0.05, 0.25), (0, 0.001)]\n",
    "feature_normalize1 = torch.zeros_like(feature1)\n",
    "feature_normalize2 = torch.zeros_like(feature2)\n",
    "for i in range(7):\n",
    "    minvalue, maxvalue = ranges[i]\n",
    "    feature_normalize1[:, i] = (feature1[:, i] - minvalue) / (maxvalue - minvalue)\n",
    "    feature_normalize2[:, i] = (feature2[:, i] - minvalue) / (maxvalue - minvalue)\n",
    "\n",
    "feature_normalize1 = torch.hstack((feature_normalize1, normallength_normalize))\n",
    "feature_normalize2 = torch.hstack((feature_normalize2, randomlength_normalize))\n",
    "\n",
    "t1 = torch.linspace(0, 1, 1150).reshape(1150, 1)\n",
    "t_s = t1.to(device)\n",
    "\n",
    "frac_num1 = int(kapaori1.shape[0] * 0.7)\n",
    "frac_num2 = int(kapaori2.shape[0] * 0.7)\n",
    "# frac_num2 = int(kapaori2.shape[0] * 0.8)\n",
    "train_feature1, test_feature1 = feature_normalize1[:frac_num1], feature_normalize1[frac_num1:]\n",
    "train_feature2, test_feature2 = feature_normalize2[:frac_num2], feature_normalize2[frac_num2:]\n",
    "\n",
    "train_kapaori1, test_kapaori1 = kapaori1[:frac_num1], kapaori1[frac_num1:]\n",
    "train_kapaori2, test_kapaori2 = kapaori2[:frac_num2], kapaori2[frac_num2:]\n",
    "\n",
    "train_kapa1, test_kapa1 = kapa1[:frac_num1], kapa1[frac_num1:]\n",
    "train_kapa2, test_kapa2 = kapa2[:frac_num2], kapa2[frac_num2:]\n",
    "\n",
    "train_feature = torch.vstack((train_feature1, train_feature2))\n",
    "test_feature = torch.vstack((test_feature1, test_feature2))\n",
    "train_kapaori = torch.vstack((train_kapaori1, train_kapaori2))\n",
    "test_kapaori = torch.vstack((test_kapaori1, test_kapaori2))\n",
    "train_kapa = torch.vstack((train_kapa1, train_kapa2))\n",
    "test_kapa = torch.vstack((test_kapa1, test_kapa2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(train_kapaori.cpu().numpy(), axis=0)\n",
    "centered_data = train_kapaori.cpu().numpy() - mean[None, :]\n",
    "covariance_matrix = np.cov(centered_data, rowvar=False)\n",
    "eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
    "basis = eigenvectors\n",
    "\n",
    "basis = torch.from_numpy(basis).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (train_kapaori, train_feature, t_s)\n",
    "y_train = train_kapa\n",
    "x_test = (test_kapaori, test_feature, t_s)\n",
    "y_test = test_kapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x1 = self.data[0]\n",
    "        x2 = self.data[1]\n",
    "        x3 = self.data[2]\n",
    "        x11 = x1[idx]\n",
    "        x22 = x2[idx]\n",
    "        x33 = x3\n",
    "        labels = self.label[idx]\n",
    "        x = (x11, x22, x33)\n",
    "        return x, labels\n",
    "\n",
    "train_loader = DataLoader(CustomDataset(x_train, y_train), batch_size = 64, shuffle = True)\n",
    "test_loader = DataLoader(CustomDataset(x_test, y_test), batch_size = 64, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNN(nn.Module):\n",
    "    def __init__(self, layer_sizes):\n",
    "        super().__init__()\n",
    "        self.dense = nn.ModuleList()\n",
    "        for i in range(1, len(layer_sizes) - 1):\n",
    "            self.dense.append(\n",
    "                nn.Linear(in_features = layer_sizes[i - 1], out_features = layer_sizes[i])\n",
    "            )\n",
    "            self.dense.append(nn.Tanh())\n",
    "        self.dense.append(\n",
    "            nn.Linear(in_features = layer_sizes[-2], out_features = layer_sizes[-1])\n",
    "        )\n",
    "        # self.dense.append(nn.Tanh())\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        y = inputs\n",
    "        for layer in self.dense:\n",
    "            y = layer(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MIONet(nn.Module):\n",
    "    def __init__(self, branch1, branch2, branch3, branch4, branch5, basis, layers1, layers2, layers3):\n",
    "        super().__init__()\n",
    "        self.branch1 = branch1\n",
    "        self.branch2 = branch2\n",
    "        self.branch3 = branch3\n",
    "        self.branch4 = branch4\n",
    "        self.branch5 = branch5\n",
    "        self.basis = basis\n",
    "        self.linears1 = torch.nn.ModuleList([torch.nn.Linear(layers1[i], layers1[i+1]) for i in range(len(layers1)-1)])\n",
    "        self.linears2 = torch.nn.ModuleList([torch.nn.Linear(layers2[i], layers2[i+1]) for i in range(len(layers2)-1)]) \n",
    "        self.linears3 = torch.nn.ModuleList([torch.nn.Linear(layers3[i], layers3[i+1]) for i in range(len(layers3)-1)]) \n",
    "        self.layers1 = layers1\n",
    "        self.layers2 = layers2\n",
    "        self.layers3 = layers3\n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction = 'mean')\n",
    "        # self.b = nn.parameter.Parameter(torch.zeros(1, 1150))\n",
    "        self.w = nn.parameter.Parameter(torch.tensor(1.0))\n",
    "\n",
    "    def forward0(self, inputs):\n",
    "        x_func1, x_func2, x_loc = inputs\n",
    "        if len(x_loc.shape) == 3:\n",
    "            x_loc = x_loc[0, :]\n",
    "        else:\n",
    "            x_loc = x_loc\n",
    "        x_loc = torch.hstack((x_loc, torch.sin(x_loc * 2 * torch.pi * self.w), torch.cos(x_loc * 2 * torch.pi * self.w), torch.sin(2 * x_loc * 2 * torch.pi * self.w), torch.cos(2 * x_loc * 2 * torch.pi * self.w)))\n",
    "        H1 = self.branch1(x_func1)\n",
    "        H2 = self.branch2(x_func2)\n",
    "        H3 = self.branch3(x_loc)\n",
    "        H3 = self.branch4(torch.transpose(H3, 0, 1)) # [1, 100]\n",
    "\n",
    "        return H1, H2, H3\n",
    "    \n",
    "    def forward1(self, inputs):\n",
    "        H1, H2, H3 = self.forward0(inputs)\n",
    "        h = inputs[0]\n",
    "\n",
    "        for i in range(len(self.layers1) - 2):\n",
    "            z = self.activation(self.linears1[i](h))\n",
    "            # h = ((1 - z) * H1 + z * H2) * H3\n",
    "            h1 = (1 - z) * H1 + z * H3\n",
    "            h2 = (1 - z) * H2 + z * H3 \n",
    "            h = h1 + h2\n",
    "        a = self.linears1[-1](h)\n",
    "        return a\n",
    "    \n",
    "    def forward2(self, inputs):\n",
    "        H1, H2, H3 = self.forward0(inputs)\n",
    "        h = inputs[1]\n",
    "  \n",
    "        for i in range(len(self.layers2) - 2):\n",
    "            z = self.activation(self.linears2[i](h))\n",
    "            # h = ((1 - z) * H1 + z * H2) * H3\n",
    "            h1 = (1 - z) * H1 + z * H3\n",
    "            h2 = (1 - z) * H2 + z * H3 \n",
    "            h = h1 + h2\n",
    "        a = self.linears2[-1](h)\n",
    "        return a\n",
    "\n",
    "    def forward3(self, inputs):\n",
    "        x_loc = inputs[2]\n",
    "        if len(x_loc.shape) == 3:\n",
    "            x_loc = x_loc[0, :]\n",
    "        else:\n",
    "            x_loc = x_loc\n",
    "\n",
    "        x_loc = torch.hstack((x_loc, torch.sin(x_loc * 2 * torch.pi * self.w), torch.cos(x_loc * 2 * torch.pi * self.w), torch.sin(2 * x_loc * 2 * torch.pi * self.w), torch.cos(2 * x_loc * 2 * torch.pi * self.w)))\n",
    "        h = x_loc\n",
    "\n",
    "        # basis2 = compute_eigenvectors(inputs[0])\n",
    "\n",
    "        for i in range(len(self.layers3) - 2):\n",
    "            z = self.activation(self.linears3[i](h)) # [50, 50]\n",
    "            h = z\n",
    "        a = self.linears3[-1](h)\n",
    "        return a\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x_func2 = inputs[1]\n",
    "        x_loc = inputs[2]\n",
    "        if len(x_loc.shape) == 3:\n",
    "            x_loc = x_loc[0, :]\n",
    "        else:\n",
    "            x_loc = x_loc\n",
    "        \n",
    "        y_func1 = self.forward1(inputs)\n",
    "        y_func2 = self.forward2(inputs)\n",
    "        y_loc = self.forward3(inputs)\n",
    "        x_merger = torch.mul(y_func1, y_func2)\n",
    "        y_func = x_merger\n",
    "        y_loc = torch.cat((self.basis, y_loc), axis = 1)\n",
    "        b = self.branch5(x_func2)\n",
    "        # y_loc = y_loc\n",
    "        y1 = torch.einsum(\"ip, jp -> ij\", y_func, y_loc)\n",
    "        y = y1 + b\n",
    "\n",
    "        return y\n",
    "    \n",
    "    def loss(self, inputs, outputs):\n",
    "        out = self.forward(inputs)\n",
    "        loss1 = self.loss_function(out, outputs)\n",
    "        loss2 = torch.mean(out[:, 0] ** 2) + torch.mean(out[:, -1] ** 2)\n",
    "\n",
    "        diff1 = (out[:, :-2] - 2 * out[:, 1:-1] + out[:, 2:]) / 10\n",
    "        smooth_loss = torch.mean(diff1 ** 2)\n",
    "        return loss1 + loss2 + smooth_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes1 = [1150, 2300, 2300]\n",
    "layer_sizes2 = [8, 2300, 2300]\n",
    "layer_sizes3 = [5, 1]\n",
    "layer_sizes4 = [1150, 2300]\n",
    "layer_sizes5 = [8, 1500, 1500, 1150]\n",
    "\n",
    "branch1 = FNN(layer_sizes1).to(device)\n",
    "branch2 = FNN(layer_sizes2).to(device)\n",
    "branch3 = FNN(layer_sizes3).to(device)\n",
    "branch4 = FNN(layer_sizes4).to(device)\n",
    "branch5 = FNN(layer_sizes5).to(device)\n",
    "\n",
    "layers1 = [1150, 2300, 2300, 2300, 2300, 2300]\n",
    "layers2 = [8, 2300, 2300, 2300, 2300, 2300]\n",
    "# layers3 = [3, 50, 50, 50, 50, 50]\n",
    "layers3 = [5, 1150, 1150, 1150, 1150, 1150]\n",
    "\n",
    "lr = 1e-5\n",
    "model = MIONet(branch1, branch2, branch3, branch4, branch5, basis, layers1, layers2, layers3).to(device)\n",
    "# model = MIONet(branch1, branch2, basis, trunk).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr, weight_decay = 0.0003)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 1000, gamma = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MIONet(\n",
       "  (branch1): FNN(\n",
       "    (dense): ModuleList(\n",
       "      (0): Linear(in_features=1150, out_features=2300, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=2300, out_features=2300, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (branch2): FNN(\n",
       "    (dense): ModuleList(\n",
       "      (0): Linear(in_features=8, out_features=1500, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=1500, out_features=2300, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (branch3): FNN(\n",
       "    (dense): ModuleList(\n",
       "      (0): Linear(in_features=5, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (branch4): FNN(\n",
       "    (dense): ModuleList(\n",
       "      (0): Linear(in_features=1150, out_features=2300, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (branch5): FNN(\n",
       "    (dense): ModuleList(\n",
       "      (0): Linear(in_features=8, out_features=1500, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=1500, out_features=1500, bias=True)\n",
       "      (3): Tanh()\n",
       "      (4): Linear(in_features=1500, out_features=1150, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (linears1): ModuleList(\n",
       "    (0): Linear(in_features=1150, out_features=2300, bias=True)\n",
       "    (1-4): 4 x Linear(in_features=2300, out_features=2300, bias=True)\n",
       "  )\n",
       "  (linears2): ModuleList(\n",
       "    (0): Linear(in_features=8, out_features=2300, bias=True)\n",
       "    (1-4): 4 x Linear(in_features=2300, out_features=2300, bias=True)\n",
       "  )\n",
       "  (linears3): ModuleList(\n",
       "    (0): Linear(in_features=5, out_features=1150, bias=True)\n",
       "    (1-4): 4 x Linear(in_features=1150, out_features=1150, bias=True)\n",
       "  )\n",
       "  (activation): Tanh()\n",
       "  (loss_function): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def initialize_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        torch.nn.init.xavier_normal_(m.weight.data)\n",
    "model.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_error(y_true, y_pred):\n",
    "    mae = torch.mean(torch.abs(y_true - y_pred))\n",
    "    return mae\n",
    "\n",
    "def standard_deviation_error(y_true, y_pred):\n",
    "    sdm = torch.std(y_true - y_pred)\n",
    "    return sdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++ 1000 +++++++++++++\n",
      "loss is:  0.019145004\n",
      "test_loss is:  0.027126555020610493\n",
      "+++++++++++++ 2000 +++++++++++++\n",
      "loss is:  0.0005271784\n",
      "test_loss is:  0.0013933835628752906\n",
      "min_loss is:  0.00044686018 loss is 0.000687844876665622\n",
      "min_loss is:  0.00037870606 loss is 0.0006984383799135685\n",
      "min_loss is:  0.00031623818 loss is 0.0006919117683234314\n",
      "min_loss is:  0.00029827835 loss is 0.0006957636020767192\n",
      "min_loss is:  0.00029467142 loss is 0.0006631536719699701\n",
      "min_loss is:  0.0002825747 loss is 0.0006609913931849102\n",
      "min_loss is:  0.00027947806 loss is 0.0006737061194144189\n",
      "min_loss is:  0.00027545524 loss is 0.0006927875219844282\n",
      "min_loss is:  0.00027437595 loss is 0.0006736946719077727\n",
      "+++++++++++++ 3000 +++++++++++++\n",
      "loss is:  0.00030352015\n",
      "test_loss is:  0.0006754835291455189\n",
      "min_loss is:  0.00026668716 loss is 0.0006795131484977901\n",
      "min_loss is:  0.00026645054 loss is 0.0006625154443706075\n",
      "min_loss is:  0.000250544 loss is 0.0006500892923213542\n",
      "min_loss is:  0.0002432963 loss is 0.0006023494255108138\n",
      "min_loss is:  0.00023954042 loss is 0.0006194213638082147\n",
      "min_loss is:  0.0002350771 loss is 0.0005998779088258743\n",
      "min_loss is:  0.00023420108 loss is 0.000596674430804948\n",
      "+++++++++++++ 4000 +++++++++++++\n",
      "loss is:  0.0003702468\n",
      "test_loss is:  0.000587996367054681\n",
      "min_loss is:  0.0002255925 loss is 0.0005582713832457861\n",
      "min_loss is:  0.00021729991 loss is 0.0005625093472190201\n",
      "+++++++++++++ 5000 +++++++++++++\n",
      "loss is:  0.00044430775\n",
      "test_loss is:  0.0005912874088001748\n"
     ]
    }
   ],
   "source": [
    "steps = 5000\n",
    "min_loss = 0.0006\n",
    "loss_list = []\n",
    "test_loss_list = []\n",
    "for i in range(steps):\n",
    "    model.train()\n",
    "    for inputs, outputs in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(inputs, outputs)\n",
    "        loss.backward(retain_graph = True)\n",
    "        optimizer.step()\n",
    "    loss_list.append(loss.item())\n",
    "    scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    total_test_loss = 0\n",
    "    total_test_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, outputs in test_loader:\n",
    "            test_loss = model.loss(inputs, outputs)\n",
    "            total_test_loss += test_loss.item() * len(inputs)\n",
    "            total_test_samples += len(inputs)\n",
    "\n",
    "        average_test_loss = total_test_loss / total_test_samples\n",
    "        test_loss_list.append(average_test_loss)\n",
    "\n",
    "    if (i + 1) % 1000 == 0:\n",
    "        print('+++++++++++++', i + 1, '+++++++++++++')\n",
    "        print('loss is: ', loss.detach().cpu().numpy())\n",
    "        print('test_loss is: ', average_test_loss)\n",
    "\n",
    "    if loss < min_loss and average_test_loss < 0.0007:\n",
    "        min_loss = loss\n",
    "        torch.save(model.state_dict(), 'model1.pth')\n",
    "        print('min_loss is: ', min_loss.detach().cpu().numpy(), 'loss is', average_test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mae: tensor(0.0153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "sdm: tensor(0.0233, device='cuda:0', grad_fn=<StdBackward0>)\n",
      "r2: tensor(0.9512, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "y_pred1 = model.forward(x_train)\n",
    "y_pred2 = model.forward(x_test)\n",
    "y_pred = torch.vstack((y_pred1, y_pred2))\n",
    "\n",
    "y_true = torch.vstack((y_train, y_test))\n",
    "\n",
    "y_pred = y_pred2\n",
    "y_true = test_kapa\n",
    "\n",
    "residual = y_pred - y_true\n",
    "r2_values = torch.empty(y_pred.shape[0])\n",
    "for i in range(y_pred.shape[0]):\n",
    "    r2_values[i] = 1 - torch.sum(residual[i, :] ** 2) / torch.sum((y_true[i, :] - torch.mean(y_true[i, :])) ** 2)\n",
    "\n",
    "average_r2 = r2_values.mean()\n",
    "\n",
    "mae1 = mean_absolute_error(y_true, y_pred)\n",
    "sdm1 = standard_deviation_error(y_true, y_pred)\n",
    "mse = torch.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "print('mse:', mse)\n",
    "print('mae:', mae1)\n",
    "print('sdm:', sdm1)\n",
    "print('r2:', average_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
