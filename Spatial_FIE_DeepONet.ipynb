{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = pd.read_excel('normaldata.xlsx', header = None).to_numpy()\n",
    "random = pd.read_excel('randomdata.xlsx', header = None).to_numpy()\n",
    "\n",
    "normalt = pd.read_excel('normalt.xlsx', header = None).to_numpy()\n",
    "randomt = pd.read_excel('randomt.xlsx', header = None).to_numpy()\n",
    "\n",
    "normalkapa = pd.read_excel('normalkapa.xlsx', header = None).to_numpy()\n",
    "randomkapa = pd.read_excel('randomkapa.xlsx', header = None).to_numpy()\n",
    "\n",
    "normalkapaori = pd.read_excel('normalkapaori.xlsx', header = None).to_numpy()\n",
    "randomkapaori = pd.read_excel('randomkapaori.xlsx', header = None).to_numpy()\n",
    "\n",
    "normaltau = pd.read_excel('normaltau.xlsx', header = None).to_numpy()\n",
    "randomtau = pd.read_excel('randomtau.xlsx', header = None).to_numpy()\n",
    "\n",
    "normaltauori = pd.read_excel('normaltauori.xlsx', header = None).to_numpy()\n",
    "randomtauori = pd.read_excel('randomtauori.xlsx', header = None).to_numpy()\n",
    "\n",
    "normal = torch.from_numpy(normal).float().to(device)\n",
    "random = torch.from_numpy(random).float().to(device)\n",
    "\n",
    "normalt = torch.from_numpy(normalt).float().to(device)\n",
    "randomt = torch.from_numpy(randomt).float().to(device)\n",
    "\n",
    "normalkapa = torch.from_numpy(normalkapa).float().to(device)\n",
    "randomkapa = torch.from_numpy(randomkapa).float().to(device)\n",
    "\n",
    "normalkapaori = torch.from_numpy(normalkapaori).float().to(device)\n",
    "randomkapaori = torch.from_numpy(randomkapaori).float().to(device)\n",
    "\n",
    "normaltau = torch.from_numpy(normaltau).float().to(device)\n",
    "randomtau = torch.from_numpy(randomtau).float().to(device)\n",
    "\n",
    "normaltauori = torch.from_numpy(normaltauori).float().to(device)\n",
    "randomtauori = torch.from_numpy(randomtauori).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get lengths of all tubes\n",
    "normallength1 = (normalt[:, 9] + normalt[:, 19] + normalt[:, 29] + normalt[:, 39] + normalt[:, 49]) * normal[:, 4]\n",
    "R1, R2, R3, R4 = normal[:, 6], normal[:, 6], normal[:, 7], normal[:, 8]\n",
    "P1, P2, P3, P4 = normal[:, 9], normal[:, 10], normal[:, 10], normal[:, 11]\n",
    "length2 = torch.sqrt((2 * torch.pi * R1) ** 2 + P1 ** 2) / (2 * torch.pi) * (normal[:, 17] / 180 * torch.pi)\n",
    "length3 = torch.sqrt((2 * torch.pi * R2) ** 2 + P2 ** 2) / (2 * torch.pi) * (normal[:, 18] / 180 * torch.pi)\n",
    "length4 = torch.sqrt((2 * torch.pi * R3) ** 2 + P3 ** 2) / (2 * torch.pi) * (normal[:, 19] / 180 * torch.pi)\n",
    "length5 = torch.sqrt((2 * torch.pi * R4) ** 2 + P4 ** 2) / (2 * torch.pi) * (normal[:, 20] / 180 * torch.pi)\n",
    "normallength = normallength1 + length2 + length3 + length4 + length5\n",
    "\n",
    "randomlength = (randomt[:, 109] + randomt[:, 119]) * random[:, 4]\n",
    "\n",
    "normallength = normallength.unsqueeze(1)\n",
    "randomlength = randomlength.unsqueeze(1)\n",
    "\n",
    "normallength_normalize = normallength / 1000\n",
    "randomlength_normalize = randomlength / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index1 = [0, 1, 2, 3, 4, 5, 21]\n",
    "index2 = [0, 1, 2, 3, 4, 5, 25]\n",
    "\n",
    "feature1 = normal[:, index1]\n",
    "kapaori1 = normalkapaori * 100\n",
    "kapa1 = normalkapa * 100\n",
    "tauori1 = normaltauori * 200\n",
    "tau1 = normaltau * 200\n",
    "\n",
    "feature2 = random[:, index2]\n",
    "kapaori2 = randomkapaori * 100\n",
    "kapa2 = randomkapa * 100\n",
    "tauori2 = randomtauori * 200\n",
    "tau2 = randomtau * 200\n",
    "\n",
    "ranges = [(20, 35), (0.075, 0.1), (1.3, 1.6), (1.05, 1.35), (40, 100), (0.05, 0.25), (0, 0.001)]\n",
    "feature_normalize1 = torch.zeros_like(feature1)\n",
    "feature_normalize2 = torch.zeros_like(feature2)\n",
    "for i in range(7):\n",
    "    minvalue, maxvalue = ranges[i]\n",
    "    feature_normalize1[:, i] = (feature1[:, i] - minvalue) / (maxvalue - minvalue)\n",
    "    feature_normalize2[:, i] = (feature2[:, i] - minvalue) / (maxvalue - minvalue)\n",
    "\n",
    "feature_normalize1 = torch.hstack((feature_normalize1, normallength_normalize))\n",
    "feature_normalize2 = torch.hstack((feature_normalize2, randomlength_normalize))\n",
    "\n",
    "t1 = torch.linspace(0, 1, 1200).reshape(1200, 1)\n",
    "t_s = t1.to(device)\n",
    "\n",
    "frac_num1 = int(kapaori1.shape[0] * 0.7)\n",
    "frac_num2 = int(kapaori2.shape[0] * 0.7)\n",
    "# frac_num2 = int(kapaori2.shape[0] * 0.8)\n",
    "train_feature1, test_feature1 = feature_normalize1[:frac_num1], feature_normalize1[frac_num1:]\n",
    "train_feature2, test_feature2 = feature_normalize2[:frac_num2], feature_normalize2[frac_num2:]\n",
    "\n",
    "train_kapaori1, test_kapaori1 = kapaori1[:frac_num1], kapaori1[frac_num1:]\n",
    "train_kapaori2, test_kapaori2 = kapaori2[:frac_num2], kapaori2[frac_num2:]\n",
    "\n",
    "train_kapa1, test_kapa1 = kapa1[:frac_num1], kapa1[frac_num1:]\n",
    "train_kapa2, test_kapa2 = kapa2[:frac_num2], kapa2[frac_num2:]\n",
    "\n",
    "train_tauori1, test_tauori1 = tauori1[:frac_num1], tauori1[frac_num1:]\n",
    "train_tauori2, test_tauori2 = tauori2[:frac_num2], tauori2[frac_num2:]\n",
    "\n",
    "train_tau1, test_tau1 = tau1[:frac_num1], tau1[frac_num1:]\n",
    "train_tau2, test_tau2 = tau2[:frac_num2], tau2[frac_num2:]\n",
    "\n",
    "train_feature = torch.vstack((train_feature1, train_feature2))\n",
    "test_feature = torch.vstack((test_feature1, test_feature2))\n",
    "train_kapaori = torch.vstack((train_kapaori1, train_kapaori2))\n",
    "test_kapaori = torch.vstack((test_kapaori1, test_kapaori2))\n",
    "train_kapa = torch.vstack((train_kapa1, train_kapa2))\n",
    "test_kapa = torch.vstack((test_kapa1, test_kapa2))\n",
    "train_tauori = torch.vstack((train_tauori1, train_tauori2))\n",
    "test_tauori = torch.vstack((test_tauori1, test_tauori2))\n",
    "train_tau = torch.vstack((train_tau1, train_tau2))\n",
    "test_tau = torch.vstack((test_tau1, test_tau2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(train_kapaori.cpu().numpy(), axis=0)\n",
    "centered_data = train_kapaori.cpu().numpy() - mean[None, :]\n",
    "covariance_matrix = np.cov(centered_data, rowvar=False)\n",
    "eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
    "basis = eigenvectors\n",
    "\n",
    "basis = torch.from_numpy(basis).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (train_kapaori, train_tauori, train_feature, t_s)\n",
    "y_train = train_kapa\n",
    "x_test = (test_kapaori, test_tauori, test_feature, t_s)\n",
    "y_test = test_kapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x1 = self.data[0]\n",
    "        x2 = self.data[1]\n",
    "        x3 = self.data[2]\n",
    "        x4 = self.data[3]\n",
    "        x11 = x1[idx]\n",
    "        x22 = x2[idx]\n",
    "        x33 = x3[idx]\n",
    "        x44 = x4\n",
    "        labels = self.label[idx]\n",
    "        x = (x11, x22, x33, x44)\n",
    "        return x, labels\n",
    "\n",
    "train_loader = DataLoader(CustomDataset(x_train, y_train), batch_size = 64, shuffle = True)\n",
    "test_loader = DataLoader(CustomDataset(x_test, y_test), batch_size = 64, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNN(nn.Module):\n",
    "    def __init__(self, layer_sizes):\n",
    "        super().__init__()\n",
    "        self.dense = nn.ModuleList()\n",
    "        for i in range(1, len(layer_sizes) - 1):\n",
    "            self.dense.append(\n",
    "                nn.Linear(in_features = layer_sizes[i - 1], out_features = layer_sizes[i])\n",
    "            )\n",
    "            # self.dense.append(nn.BatchNorm1d(layer_sizes[i]))\n",
    "            self.dense.append(nn.Tanh())\n",
    "            # self.dense.append(nn.Dropout(p = 0.2))\n",
    "        self.dense.append(\n",
    "            nn.Linear(in_features = layer_sizes[-2], out_features = layer_sizes[-1])\n",
    "        )\n",
    "        # self.dense.append(nn.Tanh())\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        y = inputs\n",
    "        for layer in self.dense:\n",
    "            y = layer(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MIONet(nn.Module):\n",
    "    def __init__(self, branch1, branch2, branch3, branch4, branch5, branch6, basis, layers1, layers2, layers3, layers4):\n",
    "        super().__init__()\n",
    "        self.branch1 = branch1\n",
    "        self.branch2 = branch2\n",
    "        self.branch3 = branch3\n",
    "        self.branch4 = branch4\n",
    "        self.branch5 = branch5\n",
    "        self.branch6 = branch6\n",
    "        self.basis = basis\n",
    "        self.linears1 = torch.nn.ModuleList([torch.nn.Linear(layers1[i], layers1[i+1]) for i in range(len(layers1)-1)])\n",
    "        self.linears2 = torch.nn.ModuleList([torch.nn.Linear(layers2[i], layers2[i+1]) for i in range(len(layers2)-1)]) \n",
    "        self.linears3 = torch.nn.ModuleList([torch.nn.Linear(layers3[i], layers3[i+1]) for i in range(len(layers3)-1)]) \n",
    "        self.linears4 = torch.nn.ModuleList([torch.nn.Linear(layers4[i], layers4[i+1]) for i in range(len(layers4)-1)]) \n",
    "        self.layers1 = layers1\n",
    "        self.layers2 = layers2\n",
    "        self.layers3 = layers3\n",
    "        self.layers4 = layers4\n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction = 'mean')\n",
    "        self.w = nn.parameter.Parameter(torch.tensor(1.0))\n",
    "\n",
    "    def forward0(self, inputs):\n",
    "        x_func1, x_func2, x_func3, x_loc = inputs\n",
    "        if len(x_loc.shape) == 3:\n",
    "            x_loc = x_loc[0, :]\n",
    "        else:              \n",
    "            x_loc = x_loc\n",
    "        x_loc = torch.hstack((x_loc, torch.sin(x_loc * 2 * torch.pi * self.w), torch.cos(x_loc * 2 * torch.pi * self.w), torch.sin(2 * x_loc * 2 * torch.pi * self.w), torch.cos(2 * x_loc * 2 * torch.pi * self.w), torch.sin(3 * x_loc * 2 * torch.pi * self.w), torch.cos(3 * x_loc * 2 * torch.pi * self.w), torch.sin(4 * x_loc * 2 * torch.pi * self.w), torch.cos(4 * x_loc * 2 * torch.pi * self.w), torch.sin(5 * x_loc * 2 * torch.pi * self.w), torch.cos(5 * x_loc * 2 * torch.pi * self.w)))\n",
    "        H1 = self.branch1(x_func1)\n",
    "        H2 = self.branch2(x_func2)\n",
    "        H3 = self.branch3(x_func3)\n",
    "        H4 = self.branch4(x_loc)\n",
    "        H4 = self.branch5(torch.transpose(H4, 0, 1)) # [1, 100]\n",
    "\n",
    "        return H1, H2, H3, H4\n",
    "    \n",
    "    def forward1(self, inputs):\n",
    "        H1, H2, H3, H4 = self.forward0(inputs)\n",
    "        h = inputs[0]\n",
    "\n",
    "        for i in range(len(self.layers1) - 2):\n",
    "            z = self.activation(self.linears1[i](h))\n",
    "            # h = ((1 - z) * H1 + z * H2) * H3\n",
    "            h1 = (1 - z) * H1 + z * H4\n",
    "            h2 = (1 - z) * H2 + z * H4\n",
    "            h3 = (1 - z) * H3 + z * H4\n",
    "            h = h1 + h2 + h3\n",
    "        a = self.linears1[-1](h)\n",
    "        return a\n",
    "    \n",
    "    def forward2(self, inputs):\n",
    "        H1, H2, H3, H4 = self.forward0(inputs)\n",
    "        h = inputs[1]\n",
    "  \n",
    "        for i in range(len(self.layers2) - 2):\n",
    "            z = self.activation(self.linears2[i](h))\n",
    "            # h = ((1 - z) * H1 + z * H2) * H3\n",
    "            h1 = (1 - z) * H1 + z * H4\n",
    "            h2 = (1 - z) * H2 + z * H4\n",
    "            h3 = (1 - z) * H3 + z * H4\n",
    "            h = h1 + h2 + h3\n",
    "        a = self.linears2[-1](h)\n",
    "        return a\n",
    "    \n",
    "    def forward3(self, inputs):\n",
    "        H1, H2, H3, H4 = self.forward0(inputs)\n",
    "        h = inputs[2]\n",
    "  \n",
    "        for i in range(len(self.layers3) - 2):\n",
    "            z = self.activation(self.linears3[i](h))\n",
    "            # h = ((1 - z) * H1 + z * H2) * H3\n",
    "            h1 = (1 - z) * H1 + z * H4\n",
    "            h2 = (1 - z) * H2 + z * H4\n",
    "            h3 = (1 - z) * H3 + z * H4\n",
    "            h = h1 + h2 + h3\n",
    "        a = self.linears3[-1](h)\n",
    "        return a\n",
    "\n",
    "    def forward4(self, inputs):\n",
    "        x_loc = inputs[3]\n",
    "        if len(x_loc.shape) == 3:\n",
    "            x_loc = x_loc[0, :]\n",
    "        else:\n",
    "            x_loc = x_loc\n",
    "        x_loc = torch.hstack((x_loc, torch.sin(x_loc * 2 * torch.pi * self.w), torch.cos(x_loc * 2 * torch.pi * self.w), torch.sin(2 * x_loc * 2 * torch.pi * self.w), torch.cos(2 * x_loc * 2 * torch.pi * self.w), torch.sin(3 * x_loc * 2 * torch.pi * self.w), torch.cos(3 * x_loc * 2 * torch.pi * self.w), torch.sin(4 * x_loc * 2 * torch.pi * self.w), torch.cos(4 * x_loc * 2 * torch.pi * self.w), torch.sin(5 * x_loc * 2 * torch.pi * self.w), torch.cos(5 * x_loc * 2 * torch.pi * self.w))) # [50, 3]\n",
    "        h = x_loc\n",
    "\n",
    "        # basis2 = compute_eigenvectors(inputs[0])\n",
    "\n",
    "        for i in range(len(self.layers4) - 2):\n",
    "            z = self.activation(self.linears4[i](h)) # [50, 50]\n",
    "            h = z\n",
    "        a = self.linears4[-1](h)\n",
    "        return a\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x_func3 = inputs[2]\n",
    "        x_loc = inputs[3]\n",
    "        if len(x_loc.shape) == 3:\n",
    "            x_loc = x_loc[0, :]\n",
    "        else:\n",
    "            x_loc = x_loc\n",
    "        \n",
    "        y_func1 = self.forward1(inputs)\n",
    "        y_func2 = self.forward2(inputs)\n",
    "        y_func3 = self.forward3(inputs)\n",
    "        y_loc = self.forward4(inputs)\n",
    "        x_merger = torch.mul(y_func1, y_func3) + torch.mul(y_func2, y_func3)\n",
    "        # x_merger = (torch.mul(y_func1, y_func3) + torch.mul(y_func2, y_func3)) / 2\n",
    "        # x_merger = torch.mul(y_func2, y_func3)\n",
    "        y_func = x_merger\n",
    "        y_loc = torch.cat((self.basis, y_loc), axis = 1)\n",
    "        b = self.branch6(x_func3)\n",
    "        # y_loc = y_loc\n",
    "        y1 = torch.einsum(\"ip, jp -> ij\", y_func, y_loc)\n",
    "\n",
    "        y = y1 + b\n",
    "\n",
    "        return y\n",
    "    \n",
    "\n",
    "    def loss(self, inputs, outputs):\n",
    "        out = self.forward(inputs)\n",
    "        loss1 = self.loss_function(out, outputs)\n",
    "        loss2 = torch.mean(out[:, 0] ** 2) + torch.mean(out[:, -1] ** 2)\n",
    "\n",
    "        diff1 = (out[:, :-2] - 2 * out[:, 1:-1] + out[:, 2:]) / 10\n",
    "        smooth_loss = torch.mean(diff1 ** 2)\n",
    "\n",
    "        return loss1 + loss2 + smooth_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes1 = [1200, 2400, 2400]\n",
    "layer_sizes2 = [1200, 2400, 2400]\n",
    "layer_sizes3 = [8, 2400, 2400]\n",
    "# layer_sizes3 = [8, 1600, 2400]\n",
    "layer_sizes4 = [11, 1]\n",
    "layer_sizes5 = [1200, 2400, 2400]\n",
    "layer_sizes6 = [8, 2400, 2400, 1200]\n",
    "\n",
    "branch1 = FNN(layer_sizes1).to(device)\n",
    "branch2 = FNN(layer_sizes2).to(device)\n",
    "branch3 = FNN(layer_sizes3).to(device)\n",
    "branch4 = FNN(layer_sizes4).to(device)\n",
    "branch5 = FNN(layer_sizes5).to(device)\n",
    "branch6 = FNN(layer_sizes6).to(device)\n",
    "\n",
    "layers1 = [1200, 2400, 2400, 2400, 2400, 2400]\n",
    "layers2 = [1200, 2400, 2400, 2400, 2400, 2400]\n",
    "layers3 = [8, 2400, 2400, 2400, 2400, 2400]\n",
    "# layers3 = [3, 50, 50, 50, 50, 50]\n",
    "layers4 = [11, 1200, 1200, 1200, 1200, 1200]\n",
    "\n",
    "lr = 1e-5\n",
    "model = MIONet(branch1, branch2, branch3, branch4, branch5, branch6, basis, layers1, layers2, layers3, layers4).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr, weight_decay = 0.0008)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 1000, gamma = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MIONet(\n",
       "  (branch1): FNN(\n",
       "    (dense): ModuleList(\n",
       "      (0): Linear(in_features=1200, out_features=2400, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=2400, out_features=2400, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (branch2): FNN(\n",
       "    (dense): ModuleList(\n",
       "      (0): Linear(in_features=1200, out_features=2400, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=2400, out_features=2400, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (branch3): FNN(\n",
       "    (dense): ModuleList(\n",
       "      (0): Linear(in_features=8, out_features=2400, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=2400, out_features=2400, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (branch4): FNN(\n",
       "    (dense): ModuleList(\n",
       "      (0): Linear(in_features=11, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (branch5): FNN(\n",
       "    (dense): ModuleList(\n",
       "      (0): Linear(in_features=1200, out_features=2400, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=2400, out_features=2400, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (branch6): FNN(\n",
       "    (dense): ModuleList(\n",
       "      (0): Linear(in_features=8, out_features=2400, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=2400, out_features=2400, bias=True)\n",
       "      (3): Tanh()\n",
       "      (4): Linear(in_features=2400, out_features=1200, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (linears1): ModuleList(\n",
       "    (0): Linear(in_features=1200, out_features=2400, bias=True)\n",
       "    (1-4): 4 x Linear(in_features=2400, out_features=2400, bias=True)\n",
       "  )\n",
       "  (linears2): ModuleList(\n",
       "    (0): Linear(in_features=1200, out_features=2400, bias=True)\n",
       "    (1-4): 4 x Linear(in_features=2400, out_features=2400, bias=True)\n",
       "  )\n",
       "  (linears3): ModuleList(\n",
       "    (0): Linear(in_features=8, out_features=2400, bias=True)\n",
       "    (1-4): 4 x Linear(in_features=2400, out_features=2400, bias=True)\n",
       "  )\n",
       "  (linears4): ModuleList(\n",
       "    (0): Linear(in_features=11, out_features=1200, bias=True)\n",
       "    (1-4): 4 x Linear(in_features=1200, out_features=1200, bias=True)\n",
       "  )\n",
       "  (activation): Tanh()\n",
       "  (loss_function): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def initialize_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        torch.nn.init.xavier_normal_(m.weight.data)\n",
    "model.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_error(y_true, y_pred):\n",
    "    mae = torch.mean(torch.abs(y_true - y_pred))\n",
    "    return mae\n",
    "\n",
    "def standard_deviation_error(y_true, y_pred):\n",
    "    sdm = torch.std(y_true - y_pred)\n",
    "    return sdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++ 1000 +++++++++++++\n",
      "loss is:  0.014393759\n",
      "test_loss is:  0.014602222169438997\n",
      "min_loss is:  0.0013100291 loss is 0.008923216878126064\n",
      "min_loss is:  0.0012663002 loss is 0.008907788277914127\n",
      "min_loss is:  0.0011855827 loss is 0.008627714744458595\n",
      "min_loss is:  0.0010729427 loss is 0.008041825300703445\n",
      "min_loss is:  0.0010453345 loss is 0.008108576914916435\n",
      "min_loss is:  0.001013105 loss is 0.007643852693339189\n",
      "min_loss is:  0.00095575803 loss is 0.003918058161313335\n",
      "min_loss is:  0.00094354013 loss is 0.003702365638067325\n",
      "min_loss is:  0.00070240285 loss is 0.0038035587252428136\n",
      "min_loss is:  0.00063157943 loss is 0.002596271806396544\n",
      "min_loss is:  0.0006155587 loss is 0.00254555760572354\n",
      "min_loss is:  0.00048916164 loss is 0.0024658939025054374\n",
      "min_loss is:  0.00045985542 loss is 0.001495193496036033\n",
      "min_loss is:  0.00044813217 loss is 0.0013994891196489334\n",
      "min_loss is:  0.00039983654 loss is 0.001461029751226306\n",
      "min_loss is:  0.00037377555 loss is 0.0013447258000572522\n",
      "min_loss is:  0.00036821887 loss is 0.001289967253493766\n",
      "min_loss is:  0.0003489374 loss is 0.0009349123768818876\n",
      "+++++++++++++ 2000 +++++++++++++\n",
      "loss is:  0.00068112795\n",
      "test_loss is:  0.000897967799877127\n",
      "min_loss is:  0.000322539 loss is 0.000756552927972128\n",
      "+++++++++++++ 3000 +++++++++++++\n",
      "loss is:  0.00077440764\n",
      "test_loss is:  0.000806196010671556\n",
      "+++++++++++++ 4000 +++++++++++++\n",
      "loss is:  0.0010034648\n",
      "test_loss is:  0.0008240487659350038\n",
      "+++++++++++++ 5000 +++++++++++++\n",
      "loss is:  0.0012028131\n",
      "test_loss is:  0.0007938673176492254\n"
     ]
    }
   ],
   "source": [
    "steps = 5000\n",
    "min_loss = 0.004\n",
    "loss_list = []\n",
    "test_loss_list = []\n",
    "for i in range(steps):\n",
    "    model.train()\n",
    "    for inputs, outputs in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(inputs, outputs)\n",
    "        loss.backward(retain_graph = True)\n",
    "        optimizer.step()\n",
    "    loss_list.append(loss.item())\n",
    "    scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    total_test_loss = 0\n",
    "    total_test_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, outputs in test_loader:\n",
    "            test_loss = model.loss(inputs, outputs)\n",
    "            total_test_loss += test_loss.item() * len(inputs)\n",
    "            total_test_samples += len(inputs)\n",
    "\n",
    "        average_test_loss = total_test_loss / total_test_samples\n",
    "        test_loss_list.append(average_test_loss)\n",
    "\n",
    "    if (i + 1) % 1000 == 0:\n",
    "        print('+++++++++++++', i + 1, '+++++++++++++')\n",
    "        print('loss is: ', loss.detach().cpu().numpy())\n",
    "        print('test_loss is: ', average_test_loss)\n",
    "\n",
    "    if loss < min_loss and average_test_loss < 0.009:\n",
    "        min_loss = loss\n",
    "        torch.save(model.state_dict(), 'model1.pth')\n",
    "        print('min_loss is: ', min_loss.detach().cpu().numpy(), 'loss is', average_test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mae: tensor(0.0178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "sdm: tensor(0.0268, device='cuda:0', grad_fn=<StdBackward0>)\n",
      "r2: tensor(0.9417, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "y_pred1 = model.forward(x_train)\n",
    "y_pred2 = model.forward(x_test)\n",
    "y_pred = torch.vstack((y_pred1, y_pred2))\n",
    "\n",
    "# y_true = torch.vstack((y_train, y_test))\n",
    "\n",
    "y_pred = y_pred2\n",
    "y_true = y_test\n",
    "\n",
    "residual = y_pred - y_true\n",
    "r2_values = torch.empty(y_pred.shape[0])\n",
    "for i in range(y_pred.shape[0]):\n",
    "    r2_values[i] = 1 - torch.sum(residual[i, :] ** 2) / torch.sum((y_true[i, :] - torch.mean(y_true[i, :])) ** 2)\n",
    "\n",
    "average_r2 = r2_values.mean()\n",
    "\n",
    "mae1 = mean_absolute_error(y_true, y_pred)\n",
    "sdm1 = standard_deviation_error(y_true, y_pred)\n",
    "mse = torch.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "print('mse:', mse)\n",
    "print('mae:', mae1)\n",
    "print('sdm:', sdm1)\n",
    "print('r2:', average_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
